{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers transformers[torch] accelerate -U datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SEL8U4IQDE8t",
        "outputId": "e7fe8251-66a8-4267-e83f-c80dcdeac733"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]) (2.8.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgj_fDQeDaqU",
        "outputId": "7608aaf5-607f-466c-c232-ac27c0f5238c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('HF_TOKEN')\n",
        "login(api_key)"
      ],
      "metadata": {
        "id": "llzcos0VFjfo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "dpoJunbWG9UT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading model and tokenizer"
      ],
      "metadata": {
        "id": "9STBLRytGj50"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsGlXhxLC5YU",
        "outputId": "1f407a70-1394-42fc-f4df-4d58ef828912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 268098176\n"
          ]
        }
      ],
      "source": [
        "model_id = \"google/gemma-3-270m\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, torch_dtype=\"float32\")\n",
        "\n",
        "# Ensure pad_token exists\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "WBMM2RFbHUEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
        "\n",
        "# Just use train split for fine-tuning\n",
        "train_data = dataset[\"train\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "975ff86031244a83b411699fe926667f",
            "ea3517e589c84798ba875214e0be2bc5",
            "7fc6bfb8722b42d5b6e4eb64ca6e72a9",
            "6642d92af56042c4814f9194f6cf4947",
            "e26cabb36bf04a5ca06a9ab0e85f1da3",
            "ba30dde24dd041a1a2a835559c8136ca",
            "17b7bebb6e574be6b820b7a247d1ff0b",
            "670a81c195f145c7a79d1d3d2563c1d5",
            "80cb94bc21cb4bec89c5ae3cf8a8b0f2",
            "cd798df3238d44d499ae74addce98cf3",
            "a637a6d39c4c4715a5bb460f89914271",
            "dc2b574304d343bab6180acf03fb5807",
            "dd64e2eedfff416ba397f50e2ceeaaf9",
            "384abc5724eb4365a8319fd0ca1f76b7",
            "8ed0acb356ec4e14af2900e1d14fad9c",
            "efe1962e484b435280702ce18568d066",
            "062114e5391e4b51adbc98251723d51f",
            "71cd66a9eeff422eb0b722a338cdeffc",
            "e6f6de5f74c140a8a9c91906e0f8b2b8",
            "5fd13b66059e4383a5d943f95fd95a0c",
            "2019af7d01dd407c8df404cd663cd068",
            "ba690e80f9ac4618b20bb08d9374bc10",
            "3cece86c9d354191a608db64b08910d9",
            "1a51d0a0fc39460d9573e37d68a07a1b",
            "af156706f46247d5a2277c927665dce8",
            "b2119766a4db4c8e90b54c500d0bcf3b",
            "6dc9f5fabc1d42899a8de436af9aed69",
            "94dd8d64b71146a69d9b79f750999138",
            "742fbaac11d1490ca38001bb047453f8",
            "ce4aac0b76454283acec56d884f4741c",
            "e9ef30fcaee84e5ea70bebf6070da0fb",
            "70b0d64781704d8abf392095782c5abf",
            "ae5f5456fa2044a297516bc4871fde0e",
            "b540dc4d81c041aea6e173846f842170",
            "295bdc1058094524912048e2bdf85e56",
            "09c3353948cd4dc7ad56322454928195",
            "0dc1e780a7d94290b60d1345aab327c0",
            "e6bba5bed41a4a748471f586e56a9e57",
            "508bac8aa27d42a0806b871dc1647708",
            "0291835f706b45f48a4b3f36f6ef0771",
            "70162f154ca8438f996d37e74aa64848",
            "d90c4eb899984718bc6de28fdbfe03f9",
            "3a422cac759d4884a3932c356bf65dcb",
            "e8e3e83dc46b45328301f3d2b591072b",
            "e5a3ee08629e47d4987abc68b471bac0",
            "aa61201bcd104e4581ef7c4f164917bc",
            "2ee887bb96cb4f0cb1dfc3c42156aa62",
            "fdfcfd1141284dc6b26b4e3aca05928f",
            "bf4f44dbace8436790d59d8abb3e1692",
            "b818e03e7e0d46fab920571368b4ffa7",
            "f8c535338a7141a28d0fd1d2fd5022c6",
            "2bfeb3918ac04b15a5cde92948007e44",
            "1fb953798dc7452ea4db225f756bde45",
            "4aaf4b07142443c5b8d0a4431e6da298",
            "cbc9520b22894cf3a86e933d708c3d33",
            "e3fd5fa8c69d43ea93e8f9c2ec1709b5",
            "40bd231c134e421a8369631681c2dc35",
            "e6599ae8cad44900aec67083e244b224",
            "e6ce058dfd664acd9c17bbe524e357be",
            "f63a02e31eac4f5392a633ed1e0802bf",
            "066196390a274460a14f96e3985fc33e",
            "0aa7c52895164168b2fb582df65380cb",
            "cf20e7412c694c5ba8f39667becb552b",
            "1d2c811709ed45ecb951156198417263",
            "a39c1ea368704726ba2dfeb7dfc7bbce",
            "300557a3267b4d219c284302543e450e",
            "ee21cdc9d4aa4c0fb33922794c0ebbb5",
            "84da3ad87add48edb86e360dfa862e68",
            "d2d27ef6ccf44f0aa93c5df39c240942",
            "c4ba75205acc4084b9cff6644e6f7b62",
            "43a6757b73f1431091fe3b35034cf699",
            "5b3c8a31e9b846dd8199d10d8fa3ad83",
            "e0511210468946029336608699de32d4",
            "9e1b784457ce4730a519a565fb0cab9a",
            "de84cceb9f064a7caba6eba66ff437e8",
            "40548b78ca70468196f01632b9e0ee3b",
            "c1e0e04b1ea84bbbae523ccd716d26ad"
          ]
        },
        "id": "fZw5G8AwHSw8",
        "outputId": "2c9bfc20-f8c9-4f83-ed63-17bcf5f1eedd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "975ff86031244a83b411699fe926667f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/733k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc2b574304d343bab6180acf03fb5807"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3cece86c9d354191a608db64b08910d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/657k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b540dc4d81c041aea6e173846f842170"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5a3ee08629e47d4987abc68b471bac0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3fd5fa8c69d43ea93e8f9c2ec1709b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee21cdc9d4aa4c0fb33922794c0ebbb5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "cvjQX_nHHji3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    outputs = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "    )\n",
        "    outputs[\"labels\"] = outputs[\"input_ids\"].copy()  # shift labels = input_ids\n",
        "    return outputs\n",
        "\n",
        "tokenized_train = train_data.map(tokenize_function, batched=True, remove_columns=[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ab6f0fe7fd9d475da77fddd8993147a5",
            "ce4f5d5e658d48e799e18a54b6ef0819",
            "707294cfeab14f7397f856a75927688a",
            "939b6285a21f4e1ea82e6758caf1ac0b",
            "faa1cabf2d9c4aada7e06061664cacb3",
            "7d3bb4c4f9604be39becb18c34258367",
            "b42617e8e37d4812ace539c2707f27eb",
            "b802fb8150f44384aa33b2bbef7efc31",
            "3a5c9e1b62054d138534db67c8220af6",
            "f57c1d3136af4ba1a90183d480e2f12e",
            "9fe4f7a901bf4cdfb3395715334dbc8d"
          ]
        },
        "id": "85qPbedKHYvI",
        "outputId": "4697a819-1a56-4e50-fc67-f62a7b36b6c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab6f0fe7fd9d475da77fddd8993147a5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training setup"
      ],
      "metadata": {
        "id": "e8ujU853H2dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finetuned_gemma\",\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=2,  # helps with memory\n",
        "    # evaluation_strategy=\"no\",       # turn to \"epoch\" if you add validation\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=1,  # for demo, increase if needed\n",
        "    logging_steps=50,\n",
        "    fp16=torch.cuda.is_available(), # use FP16 if GPU supports it\n",
        "    report_to=\"none\",               # disable WandB logging\n",
        ")"
      ],
      "metadata": {
        "id": "TYXcJu7DHyNG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        ")"
      ],
      "metadata": {
        "id": "yX2cLngMH9yF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IU1_-CWlIB-5",
        "outputId": "f279f102-e515-45e4-b982-9382f51e95af"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2295' max='2295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2295/2295 23:04, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.305100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.228300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.269600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.287300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.191500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.243800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.361500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.237500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.219400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.172700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.149500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.289700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>1.238500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.154800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.121000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.167000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>1.281400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.191600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>1.162600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.267800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>1.157000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.214300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>1.224300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.125100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>1.200500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.098500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>1.188000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.129400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>1.118500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.126600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>1.209900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.178800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>1.175100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.225700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>1.218500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.133500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>1.153200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>1.111600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>1.155700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.137800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>1.131200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.132500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>1.225900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>1.125100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>1.128300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2295, training_loss=1.2310049202447364, metrics={'train_runtime': 1386.9463, 'train_samples_per_second': 26.474, 'train_steps_per_second': 1.655, 'total_flos': 2829135863414784.0, 'train_loss': 1.2310049202447364, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the model"
      ],
      "metadata": {
        "id": "9TleTNI-N9iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"./finetuned_gemma\""
      ],
      "metadata": {
        "id": "6ewWoEosM2W4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMwAGZokOHTS",
        "outputId": "dc52f17c-122f-4346-c9e9-8e9b5228c140"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./finetuned_gemma/tokenizer_config.json',\n",
              " './finetuned_gemma/special_tokens_map.json',\n",
              " './finetuned_gemma/tokenizer.model',\n",
              " './finetuned_gemma/added_tokens.json',\n",
              " './finetuned_gemma/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push to HuggingFace Hub"
      ],
      "metadata": {
        "id": "4IBJgVFkORHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import create_repo, HfApi, upload_folder"
      ],
      "metadata": {
        "id": "EKXKil6JPxxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create repo (only first time)\n",
        "repo_id = \"Sharath1036/gemma3-270m-finetuned\"\n",
        "create_repo(repo_id, repo_type=\"model\", exist_ok=True)"
      ],
      "metadata": {
        "id": "1G4A8SZWOXWm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "241fe5cb67d4475bb28c0ac7a392dad0",
            "4db2f3eedbf040bbab7eaed854f9e5f2",
            "0ff5fc503b044b0d81859284811ae069",
            "4fd691fc040d41eb9d326853e2767027",
            "1b401811fc654e14b38ce42c92d06e97",
            "d0ec76c167ad4277bd706521f91de115",
            "f8b60d55c99d4b8995edde7fe1377016",
            "aeef200846394cc497b47acfe00e80e2",
            "52c4fe61800e493c98ff15360912ebb8",
            "6c3cfcbc21c34ed88e7a25b3532c37d9",
            "c3269fd9f02b4c8391ff5ce54fc6a37c",
            "19445fe9a4e64871921d0d246f91b844",
            "944931001e3340d691f4c0999162ff45",
            "a44d1cc72cf04b3dbedf4c24fb2105b4",
            "83d798bc919042998a1ba043e09df3ce",
            "85d2f940468c451a91dff3881419f4d7",
            "4a6fb2bb473640ce9b873d3cca25aca4",
            "23071c4399a44e84b66696e903c884e7",
            "1708e3be703841dd8807902886ef4a37",
            "46864ce591b44dd4b7db586818a94a76",
            "72cfb8b0772545e48a673e61643973e5",
            "913cbff46f8d4e509cb92ad4c9189630",
            "4407bf9f0f4745ceadc8ffd46cf23816",
            "fd60aeda0e0c47c6abcae6fd9419c2a7",
            "435dd013ed8f4f8981c65778ff80066c",
            "a1b0583f796742c1a5af5a875bd8c4ab",
            "ab8b484e19c5433b902c24de07f1ea5d",
            "4086d94b2e5947e58ec9a0b911a72902",
            "fcd73592a027419c84d43c787f474bbf",
            "3e908189160c40a8a56a67a8af2dc77a",
            "f8afebb28d5141c08250de7512213b04",
            "eb45172cc9b14887b9ebdb1e118b39d5",
            "607de45e7310454d973d49f7ffc80d7f",
            "6c49d396107b4612b29c8222db00d615",
            "a3d792507bc04662a34246e373149467",
            "52abec50416b4da2825311f04c736b9e",
            "844b6c628d2e4f1790dd653075f350f8",
            "70f1ca53ee98443f9ea1e62ad05ac515",
            "64e0dc1d8f3b47ec9a4e7f438a8c2ade",
            "4a6bb6d9d5fb44fa8cbf299ca0eb5954",
            "b6d4421fdbf643ef9e59e858980ad941",
            "b0ac2875f33d4d9dacfc2a5fea8a03ed",
            "f000cdc2f49645cd85dd7f1b56181be7",
            "16ca4bd0840a44468d03a6c826cbb94d",
            "1c94bbf89ae1452faedd40183ee97505",
            "c6bce0551c9843e9846bb68e34f64191",
            "f0b588c6859f405f924e05a94003b53a",
            "384ace73d1e4488b89e50843b124dfef",
            "b0cf5bb26beb4f82aa80b98333ab497c",
            "b1310bb7473e48f1a7e04557aed8ae39",
            "ab31d6b268264ea4b81ff9a0aa1dac20",
            "b76be554ea5641bb87179ec15c6b1fb3",
            "e784f963f5634f8aa1ba2ae967fc86a0",
            "9acd85e00f7e4de8b1ee412b7eda4ae0",
            "8506e1f596544224bb4e24fa76f43c3b",
            "9f5d8326787048a8bd676cccc718f1f4",
            "a09534b1661b48eeaf62d2948f72a21a",
            "8fd6874da57c4b74adbe07f7db93d06d",
            "d41b738fd9c54fc9adf9be6b61f5e8d1",
            "c60ff51875f64fdd80470d4c7f0db7b9",
            "c24e2b0463f44fce8868516e93671048",
            "57fd449293cf4535a531a1729703885b",
            "a2530b768a26460085d8e8c746c97ac4",
            "46492a833da94d3d87a3b4c5cf595b10",
            "e93b1fd26da647cd8bbe45126795f574",
            "a2f0eb8b4afe4899a176d500f79296fe",
            "9b6b846a465a4d0e8eb7104322873c07",
            "5547f20b82414af489a9e6e1131f465c",
            "8cc61c828e2e4a30b2873e4841769eb0",
            "d4c1bef024fe499a9e8cbae0426c7496",
            "4450c7f5e1cd41c0ae4d835e8454e3ea",
            "315636f1f71a4158ac2b99ba2defdbb1",
            "587cd61bbe3d43dd91fe46f71bf9ac0e",
            "8d4fb1849a434686a97fd712ddc8172c",
            "52fbaae70be1449bbf64c82df38cb187",
            "6a38747a54414ef29cba0ca120922fc9",
            "3aef10c3a67a4959b7e23e69b40cfdd5",
            "a79a26341a50424caf741313481f8f91",
            "6193afff1fea4894b7d272151dee6faa",
            "7bc8cdf6931b4c93abc76b23fda4c07c",
            "c73408675b35476fb87126f1134c2f40",
            "d74a1e88004745a1880786ba7f828fc2",
            "b7d4d4b9cc9146de9da83eb83a243720",
            "800741d452d54677b74ff24f06745ff3",
            "f4a1cbb9c58c443d97e5fe4e18a5a528",
            "f76d50cfad844e8eb472da2f89e04e71",
            "ebe485991a614a5d8fd0a131906170f1",
            "28638f3542be47d0b3b89bc5d66f9c4d",
            "77e656699e454a7ab76cf6dee616e190",
            "69ec726f74304b5495c3c825b90299ed",
            "e436003980e4456e93daa3f5a0541370",
            "05ac836402e3459eb7e4e11099d892e3",
            "81754d0b4f62488a97934b19ddea0396",
            "c69ac7e66253498b96bd1eb17b14413b",
            "f625cb1e6aba45c6b7360c7b27edab0e",
            "8ada0c0950374077aafe3df1da80201e",
            "1fb3aa30b46b41acb3ca12a32f737d4b",
            "410546ad00684fbc905ac8f99c7c9010",
            "d9c066e6655248d184bfe9f7cc45f56c",
            "c5c09cac4eed459c964c89d3a1abc65e",
            "13cd19ca7c1d48b58d7320a24677454e",
            "066f1ce667374aa39b9d7c8faf1261a2",
            "6cbc28171c0d4320ab3d94edf91e3bf4",
            "b18f27b02df647f1b4076fbfb6a1a4c5",
            "e16db55ad8dd4b3db4dcb048488dabd5",
            "712615465b11463ca8234eeacc0fc7c3",
            "a3f9ed31913f4c2ebfeccacf0345322f",
            "6a7a822129a24fe0b93b7d31ea74790c",
            "cea6ba86cb04439287763ca0bcefbd44",
            "a06d307347d1486c86406d54ec19b68a",
            "36aba60151124e8bbff74b3e3009657e",
            "5ec11edaf16d4ebbb24afda972a27ead",
            "09b2f467e19d4b038f39f1cd92c0c74f",
            "83f046bae9da45d0bac517be827434c6",
            "6681661e958d4348b443a51089a87684",
            "01c027d204f64311ac9da9c47f887fda",
            "44bfe09a936c4c8b9a99ef15e56637b7",
            "ff996dd1f102491d8a015cd15da6c9d4",
            "6d0f5da732e44913a18c7992c15dab47",
            "abe37a45e57e4be5a61c190fa98d4685",
            "07cb5df352734735837585104c48059e"
          ]
        },
        "id": "d483d50d",
        "outputId": "85dc55eb-f585-47e2-91d9-b1c9b6dd3a53"
      },
      "source": [
        "api = HfApi()\n",
        "\n",
        "# Create the repository if it doesn't exist\n",
        "create_repo(repo_id, repo_type=\"model\", exist_ok=True)\n",
        "\n",
        "# Now upload the folder\n",
        "upload_folder(\n",
        "    repo_id=repo_id,\n",
        "    folder_path=output_dir,\n",
        "    commit_message=\"Upload fine-tuned Gemma 3 270M model\"\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "241fe5cb67d4475bb28c0ac7a392dad0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload                         : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "19445fe9a4e64871921d0d246f91b844"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...tent/finetuned_gemma/tokenizer.json:  25%|##4       | 8.28MB / 33.4MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4407bf9f0f4745ceadc8ffd46cf23816"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...ent/finetuned_gemma/tokenizer.model: 100%|##########| 4.69MB / 4.69MB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c49d396107b4612b29c8222db00d615"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...gemma/checkpoint-2295/rng_state.pth:  77%|#######7  | 11.3kB / 14.6kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c94bbf89ae1452faedd40183ee97505"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ..._gemma/checkpoint-2295/optimizer.pt:   0%|          |  529kB / 2.14GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f5d8326787048a8bd676cccc718f1f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...a/checkpoint-2295/model.safetensors:   0%|          |  553kB / 1.07GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b6b846a465a4d0e8eb7104322873c07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...t/finetuned_gemma/model.safetensors:   0%|          |  553kB / 1.07GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a79a26341a50424caf741313481f8f91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...ned_gemma/checkpoint-2295/scaler.pt:   6%|5         |  79.0B / 1.38kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77e656699e454a7ab76cf6dee616e190"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ..._gemma/checkpoint-2295/scheduler.pt:   6%|5         |  84.0B / 1.47kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5c09cac4eed459c964c89d3a1abc65e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...a/checkpoint-2295/training_args.bin:   6%|5         |   331B / 5.78kB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36aba60151124e8bbff74b3e3009657e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Sharath1036/gemma3-270m-finetuned/commit/2498b0c6090766c983165006c578a1ab5915d259', commit_message='Upload fine-tuned Gemma 3 270M model', commit_description='', oid='2498b0c6090766c983165006c578a1ab5915d259', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Sharath1036/gemma3-270m-finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='Sharath1036/gemma3-270m-finetuned'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the pushed model"
      ],
      "metadata": {
        "id": "xDiDre2jQj4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Sharath1036/gemma3-270m-finetuned\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Sharath1036/gemma3-270m-finetuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273,
          "referenced_widgets": [
            "3868aa3c7f4441c3bd17f31ace853b41",
            "d4b73772be55493b9633381618ce6955",
            "a3763051507c4926a3dd0185f95e962f",
            "07d2f5876f474948b80a4b485be24936",
            "e5feaa05456d4a8cbc7494cf608304e9",
            "1093a1b90fcf4cf0bece3542b4c80ffc",
            "090c361aae6e46c898c7c15e8e4b7a8f",
            "5a9d900b95014aec9f9c5d5b0e27781a",
            "b526c39bbb7141df9ccdd833e611c533",
            "d366d5ab4f1143649a554b495346e5fc",
            "0bcde933222a484aa14e533521d5f3af",
            "840ad83a8e864768895da01d6ebbf9b2",
            "d337122f14e347ef8a0642059d6c5b06",
            "e5f9ba9c887f47a5a80c41cf6a3d7b3a",
            "cb578e00476943fb93438a4c0f971790",
            "8fa43c9288cb439a846496ba1d244e13",
            "8c1dbb689f13423ab8b7e7c606e95233",
            "0872b889b92a426fb4e73a62b1f1fc32",
            "7cb0aff287814cc4bed8f4710645b9eb",
            "08960d65ba234ba88c7a6f68bf363b51",
            "10ba3eacd0c344e985ca242033560e06",
            "b6a7fb76039e4fe7a41ff5d4ac870efa",
            "7fa1f689828946dc9680724b930b6437",
            "1a7377e3472646a4ad97a09c7cbbd05e",
            "35f40f51a7224cef9285010046ef6608",
            "dd23ce9eca2a4df2b9df5e2967d043e0",
            "a6bb361b5c1c4367b7d8d433b64a5950",
            "85ee10f1db79420d88e661b0f605a255",
            "4c139514a57a4e08babf1c3db4d7aad7",
            "012c9687c4694980b02f1039156aaea5",
            "e1541e0683b941de90a07ac2fb82726f",
            "d02a05f67eb246d885c4535f54634beb",
            "0bf6737243c1465289b06fc585e24d9a",
            "4536cbe6503a4e80a8db9346f4393e74",
            "44a29e14799e40118b130a3c88a545c6",
            "be92abead16a460990fb3210478b81c4",
            "51baaec4ff7c4c80935ca121cf85f001",
            "c95381dc0f6346948eaca9944302e1d5",
            "218bfa3ccbc841718d8e43c41d2c0889",
            "9c97091afb9a49fd8f9c4425d642d2e9",
            "0d73745f4a3f43189211ecd042fb863e",
            "d72c1c33b95645b38eb27f54284f3809",
            "0ef05645d3df4eceb9b8304ee8b2da11",
            "87c42bceecc544ff826de47ec72c94d6",
            "9f8fa7cdff174ca3a9907d5df627ecaa",
            "ab30ff1f60d64b9b8f906eef34465f26",
            "a7a6ae41dc4848a380974d78ca0b1a78",
            "82b546f64fcd421a8e665c73145a10fe",
            "b403289938d14106a18b8d89deba1ccf",
            "18bc2421c6d54049967195e4452663af",
            "dc472028572f482c87c7e133ebae1ec8",
            "d38db31cb7bb49d9b5e4e692a7436efe",
            "5fb28e4f474142f5bc00e3d66a5e7157",
            "e1992a636a514c2890485c3dde40802a",
            "7fb75fe93d4b4640ac573db3f8426de9",
            "46b117d709814fb2b2ca85fe40c35762",
            "4b08bae3b75240d9929d9c894ff754ca",
            "abe60edf175e4c22b1ebeb5317fde115",
            "9d408bd628ad4572a92dd72c0ced7c78",
            "812c632e99924361bb701968b2e64acc",
            "0a79654bca70463ab2ac3be9ceac2a82",
            "ecfaca47726648b688017566202eb27c",
            "73618918b81241b989e0ca9fa995602e",
            "330fd3e1a5f649c58f3b7e4c6e122c51",
            "f2ab64e42ba546238958e6e79dd8cca5",
            "2ded77ceac52463b9a385ff5d97d8d58",
            "7ce48d52a86a443a8c54ab3ad3d93f3e",
            "7708a70540d64cd1890183dafe382506",
            "648f854420874e50a8195b58b3340374",
            "aa54043b590b405eb13697a489136ca0",
            "7846237e97b548d793d6b08ae80ddeee",
            "dd3e0c65042f479cb13ccab6d6e8b219",
            "16feae80725848599af84009c0121aac",
            "1b34e2dd60a94a408cbef1b68d4762d2",
            "5bb8721ecab4466ab3215224e3746dd6",
            "d3e31daa824349d89541c42d53bb2abc",
            "483f7a62137a474bb02d127491474297",
            "42ece3a775114ee1bfd554c1e963ea06",
            "b6a89ab0142849f6af64a5af0e502d25",
            "735facbe34954f5c82861995501e0530",
            "8d37647203a242f8813c2925e2151d4a",
            "7fb6ad62dd784e999b644f9a03d6c55b",
            "955d5a3f9a3b473e8d454d8442a182d8",
            "d2364aab5fe44dc49fd13e12ca2c3a64",
            "3b57a735c1c04dc48d54a19cafbedc7b",
            "9f92e40feaf5411e817aef435d97421f",
            "d69acfcb29b7426f9169f676ba815bdb",
            "2cc135f1fff840d3b43af90d30d3b483"
          ]
        },
        "id": "Lr9ta9jsQjEL",
        "outputId": "8e4be5ee-c039-45d0-feca-4fa352124c71"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3868aa3c7f4441c3bd17f31ace853b41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.07G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "840ad83a8e864768895da01d6ebbf9b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/128 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fa1f689828946dc9680724b930b6437"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4536cbe6503a4e80a8db9346f4393e74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f8fa7cdff174ca3a9907d5df627ecaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46b117d709814fb2b2ca85fe40c35762"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ce48d52a86a443a8c54ab3ad3d93f3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/548 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42ece3a775114ee1bfd554c1e963ea06"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Narendra Modi is an Indian politician\""
      ],
      "metadata": {
        "id": "7PYbygkQQ14e"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "zNxhfMQwQ5XG"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=500,   # length of generation\n",
        "    do_sample=True,      # sampling makes responses more natural\n",
        "    top_p=0.9,           # nucleus sampling\n",
        "    temperature=0.2      # creativity\n",
        ")"
      ],
      "metadata": {
        "id": "UwjaKg1tQ8qe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Prompt:\", prompt)\n",
        "print(\" Output:\", tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d57r12fwQ_du",
        "outputId": "fe740c06-f59f-400d-87cb-72fb4f42a5b4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Prompt: Narendra Modi is an Indian politician\n",
            " Output: Narendra Modi is an Indian politician and former Prime Minister of India . He is the President of India and the Prime Minister of India . He is the first Indian to be elected to the Indian Parliament . He is the first Indian to be elected to the Indian Parliament . \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "\n"
          ]
        }
      ]
    }
  ]
}